)
below_rows = below_rows[order(-below_rows$VIF_score_at_removal),][-1,] #remove first entry since it's already been removed
below_rows[,2] = NA
vif_rem_vals <- rbind(vif_rem_vals, below_rows)
#If you want R2 and pearson r values. Not sure how to best interpret these
if(show.R2.vals){vif_rem_vals$R2 <- 1 - 1/(vif_rem_vals$VIF_score_at_removal)
vif_rem_vals$r <- sqrt(vif_rem_vals$R2)}
#This list is ordered from first VIF to last VIF
#(i.e., first variables to be removed and first VIF tables run are at the start)
return(list(names_kept_vec, names_rem_vec, vif_rem_vals, vif_dfs))
return(list(names_kept_vec, names_rem_vec, vif_rem_vals, vif_dfs))
oss.seqvif <- function(cov_df, thresh, trace=F, show.R2.vals=F){
###Load required library or throw error
if(any(!'data.frame' %in% class(cov_df))){cov_df <- data.frame(cov_df)}
###Get initial vif value for each covariate and confirm that at least VIF is above threshold
vif_init <- NULL
for(covar in names(cov_df)){
regressors <- names(cov_df)[names(cov_df) != covar]
form <- stats::formula(paste(covar, '~', paste(regressors, collapse = '+')))
vif_init <- rbind(vif_init, c(covar, fmsb::VIF(stats::lm(form, data = cov_df))))
}
max_vif <- max(as.numeric(vif_init[,2]), na.rm = TRUE)
###If no values are above threshold, stop
if(max_vif < thresh){
print(vif_init)
message(paste("Error: All variables have VIF <", thresh, ", max VIF = ", round(max_vif,2),
". Returning table with VIF scores. Choose lower threshold to perform removal or keep all variables"))
return(vif_init)
}
###If at least one value is above threshold, run sequential VIF
else{
in_dat <- cov_df #create copy to iterate over
#Set empty vectors to store outputs
names_kept_vec <- NULL; names_rem_vec <- NULL; vif_dfs <- NULL
vif_rem_vals <- data.frame(Covariate = character(), VIF_at_removal = numeric()) #Setting as numeric doesn't really matter since it gets removed later
#Backwards selection of explanatory variables, stops when all VIF values are below 'thresh'
while(max_vif >= thresh){
if(ncol(in_dat) <= 2){print("Removed all covariates but two, stopping"); break} #If not enough covariates to do lm, stop - shouldn't this be 1?
vif_vals <- NULL
for(covar in names(in_dat)){
regressors <- names(in_dat)[names(in_dat) != covar]
form <- stats::formula(paste(covar, '~', paste(regressors, collapse = '+')))
vif_vals <- rbind(vif_vals, c(covar, fmsb::VIF(stats::lm(form, data = in_dat))))
}
#Record max value
max_vif <- max(as.numeric(vif_vals[,2]), na.rm = TRUE)
#if(length(which(vif_vals[,2] == max_vif)) > 1){paste0("VIF scores tied, removing alphabetically")} #This should be incredibly rare/impossible
max_row <- which(vif_vals[,2] == max_vif)[1]
#We need this break so it doesn't remove the next variable below the threshold
if(max_vif<thresh) break
#Print output of each iteration
if(trace){print(vif_vals); cat('\n'); cat('removed: ', vif_vals[max_row,1], max_vif,'\n\n')}
#Record names you are removing
names_rem_vec = append(names_rem_vec, vif_vals[max_row,1])
#Record the VIF value that is being removed
vif_rem_vals <- rbind(vif_rem_vals, vif_vals[max_row,])
#Remove covariate from dataframe
in_dat <- in_dat[,!names(in_dat) == vif_vals[max_row,1]]
#Store VIF table
vif_dfs <- c(vif_dfs, list(vif_vals))
}
#Record names you are keeping
names_kept_vec <- names(in_dat)
#Update columns of vif_rem_vals with covariates that were not removed during VIF because either:
#they were below threshold or because lm breaks down with 2 covariates
colnames(vif_rem_vals) <- c("Covariate", "VIF_score_at_removal")
vif_rem_vals[,2] <- as.numeric(vif_rem_vals[,2])
below_rows = data.frame(Covariate = as.character(vif_dfs[[length(vif_dfs)]][,1]),
VIF_score_at_removal = as.numeric(vif_dfs[[length(vif_dfs)]][,2])
)
below_rows = below_rows[order(-below_rows$VIF_score_at_removal),][-1,] #remove first entry since it's already been removed
below_rows[,2] = NA
vif_rem_vals <- rbind(vif_rem_vals, below_rows)
#If you want R2 and pearson r values. Not sure how to best interpret these
if(show.R2.vals){vif_rem_vals$R2 <- 1 - 1/(vif_rem_vals$VIF_score_at_removal)
vif_rem_vals$r <- sqrt(vif_rem_vals$R2)}
}
#This list is ordered from first VIF to last VIF
#(i.e., first variables to be removed and first VIF tables run are at the start)
return(list(names_kept_vec, names_rem_vec, vif_rem_vals, vif_dfs))
}
oss.seqvif(cov_df=df, thresh=5, trace=T, show.R2.vals=T)
devtools::document()
rm(oss.seqvif)
devtools::document()
devtools::check()
load_all()
#Generate autocorrelated raster layers from the Keene study area
data(keene)
##Original DEM values
orig_pts <- raster::sampleRandom(x=keene, size=1000, na.rm=TRUE, sp=FALSE)
##Create values correlated with original DEM values
ras1 <- orig_pts + rnorm(orig_pts, mean=0, sd=5)
ras2 <- orig_pts + rnorm(orig_pts, mean=0, sd=5)
ras3 <- orig_pts + rnorm(orig_pts, mean=0, sd=5)
ras4 <- orig_pts + rnorm(orig_pts, mean=0, sd=10)
ras5 <- orig_pts + rnorm(orig_pts, mean=0, sd=10)
df <- data.frame(orig_pts, ras1, ras2, ras3, ras4, ras5)
#Create values with same mean as DEM values but not correlated
random_rasters <- NULL
for(i in 1:10){
rand_ras <- rnorm(n=length(orig_pts), mean=mean(orig_pts), sd=10)
random_rasters <- cbind(random_rasters, rand_ras)
}
df <- cbind(df, random_rasters)
oss.seqvif(cov_df=df, thresh=5, trace=T, show.R2.vals=T)
devtools::document()
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::check()
library(devtools)
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::dcoument
devtools::document()
?oss.seqVIF
library(ithir)
$goof
?goof
?oss.seqVIF
devtools::document()
?oss.seqVIF
devtools::document()
devtools::document()
?oss.seqVIF
devtools::document()
devtools::document()
devtools::check()
devtools::document()
devtools::check()
devtools::document()
devtools::document()
devtools::document()
devtools::check()
#' mapply(oss.texture,sand=dat$sand, silt=dat$silt, clay=dat$clay,
#' vcs=dat$vcs, cs=dat$cs, ms=dat$ms, fs=dat$fs, vfs=dat$vfs)
#'
#' #Determine texture class for multiple observations without sand fractions
#' dat<- data.frame(sand=c(20,40,80), silt= c(15,30,10), clay= c(65,30,10))
#' mapply(oss.texture,sand=dat$sand, silt=dat$silt, clay=dat$clay)
#'
#' #or return it as a new column in the data frame
#' dat$class<- mapply(oss.texture,sand=dat$sand, silt=dat$silt, clay=dat$clay)
#'
oss.texture<- function(sand, silt, clay, vcs=NULL, cs=NULL, ms=NULL, fs=NULL, vfs=NULL, triangle="CSSC"){
clay<- clay
silt<- silt
sand<- sand
vcs<- vcs
cs<- cs
ms<- ms
fs<- fs
vfs<- vfs
# start by looking at the sums of the sand, silt and clay
psa<- sand + silt + clay
# if psa=NA, we want the function to skip to the end and return NA, so we wrap the entire thing in an if statement
if(!is.na(psa)){
# if the sum is closest to 1, meaning user has decimals, convert to percentages
if(which.min(abs(c(1,100)-psa))==1){
clay<- clay*100
silt<- silt*100
sand<- sand*100
}
# next we will ensure we normalize to 100, and print an error statement if values deviate too greatly
if (psa>=105 | psa<= 95) warning('Sum of sand, silt and clay deviates from 100 by more than 5. Check your input data. Values will be normalized to sum 100')
# and now we will normalize to 100 for the sand, silt and clay
# create copies for the calculation
clay.t<- clay; silt.t<- silt; sand.t<- sand
# and now we normalize to 100
clay<- clay.t/(clay.t+silt.t+sand.t)*100
silt<- silt.t/(clay.t+silt.t+sand.t)*100
sand<- sand.t/(clay.t+silt.t+sand.t)*100
rm(clay.t, silt.t, sand.t)
# next we look at the sums of the sand fractions, but only if we need to
if(!is.null(vcs)|!is.null(cs)|!is.null(ms)|!is.null(fs)|!is.null(vfs)){
# we need to create a warning if things are not adding up
sfrac<- vcs+cs+ms+fs+vfs
sfrac<- mean(sfrac, na.rm=TRUE)
# we check to see if sand fractions sum closer to sand content
# and we check to see if the sum deviates by more than 2 from total sand and issue warning if it does
if(which.min(abs(c(sand,100)-sfrac))==1){
if(sfrac>=(sand+5) | sfrac<= (sand-5)) warning('Sum of sand fractions deviates by more than 5 from total sand. Check your input data. Values will be normalized to sum 100')
}
# we check to see if sand fractions sum closer to 100% (reported as percent of total sand)
# and if closer to 100, we check to see if the sum deviates by more than 2 from 100
if(which.min(abs(c(sand,100)-sfrac))==2){
if(sfrac>=(105) | sfrac<= (95)) warning('Sum of sand fractions deviates by more than 5 from 100. Check your input data. Values will be normalized to sum 100')
}
# and now we will normalize sand fractions in the case they are a proportion of total sand
# create copies for the calculation
vcs.t<- vcs; cs.t<- cs; ms.t<- ms; fs.t<- fs; vfs.t<- vfs
if(which.min(c(sand,100)-sfrac)==1){
vcs<- vcs.t/(vcs.t+cs.t+ms.t+fs.t+vfs.t)*100
cs<- cs.t/(vcs.t+cs.t+ms.t+fs.t+vfs.t)*100
ms<- ms.t/(vcs.t+cs.t+ms.t+fs.t+vfs.t)*100
fs<- fs.t/(vcs.t+cs.t+ms.t+fs.t+vfs.t)*100
vfs<- vfs.t/(vcs.t+cs.t+ms.t+fs.t+vfs.t)*100
}
rm(vcs.t, cs.t, ms.t, fs.t, vfs.t)
# and now we will normalize sand fractions
# if they were just converted in last step, they will already be in percent, but it doesn't hurt
if(which.min(c(sand,100)-sfrac)==2){
vcs<- vcs*100
cs<- cs*100
ms<- ms*100
fs<- fs*100
vfs<- vfs*100
}
}else{
# if no sand fraction data is provided, we assign these dummy values which lands in the texture class
# where no sand fraction qualifier is used
vcs<-10
cs<- 10
ms<- 30
fs<- 25
vfs<-25
}
# end of the section where we manipulate the sand fractions if present
#############################################################################################################
# and here is the start of the main section where texture class is determined
if(is.na(clay) | is.na(silt) | is.na(sand)){tclass <- NA
# here we do the sands
} else if(silt + 1.5 * clay < 15){
if(vcs + cs >=25 & ms<50 & fs<50 & vfs<50){tclass<- 'coarse sand'
} else if (vcs + cs + ms >=25 & vcs + cs <25 & fs<50 & vfs<50 | vcs + cs >=25 & ms>=50){tclass<- 'sand'
} else if (fs>=50 | vcs+cs+ms<25 & vfs<50){tclass<- 'fine sand'
} else if (vfs>=50){ tclass<- 'very fine sand'
} else {tclass<- 'sands error'}
# here we do the loamy sands
}else if(silt + 1.5 * clay >= 15 & silt + 2 * clay < 30) {
if(vcs + cs >=25 & ms<50 & fs<50 & vfs<50){tclass<- 'loamy coarse sand'
} else if (vcs + cs + ms >=25 & vcs + cs <25 & fs<50 & vfs<50 | vcs + cs >=25 & ms>=50){tclass<- 'loamy sand'
} else if (fs>=50 | vfs<50 & vcs + cs + ms <25){tclass<- 'loamy fine sand'
} else if (vfs>=50){tclass<- 'loamy very fine sand'
} else {tclass<- "loamy sands error"}
# here we do the sandy loams
}else if((clay >= 7 & clay < 20 & sand > 52 & silt + 2 * clay >= 30) | (clay < 7 & silt < 50 & silt + 2 * clay >= 30)) {
if(vcs + cs >= 25 & ms<50 & fs<50 & vfs<50){tclass<- 'coarse sandy loam'
} else if (vcs + cs + ms >=30 & fs<50 & vfs<50){tclass<- 'sandy loam'
} else if (fs>=30 & vfs<30 | vcs+cs+ms>=15 & vcs+cs+ms < 30 | fs + vfs >40 & fs>=20 & vcs + cs + ms <15 ){tclass<- 'fine sandy loam'
} else if (vfs>=30 | vfs + fs >40 & vfs>=20 & vcs + cs + ms <15){tclass<- 'very fine sandy loam'
} else {tclass<- 'sandy loams error'}
# and now the sand fractions no longer matter
} else if(clay >= 7 & clay < 27 & silt >= 28 & silt < 50 & sand <= 52) {tclass<- "loam"
} else if((silt >= 50 & clay >= 12 & clay < 27) | (silt >= 50 & silt < 80 & clay < 12)) {tclass<- 'silt loam'
} else if(silt >= 80 & clay < 12) {tclass<- 'silt'
} else if(clay >= 20 & clay < 35 & silt < 28 & sand > 45) {tclass<- 'sandy clay loam'
} else if(clay >= 27 & clay < 40 & sand <= 45 & sand > 20) {tclass<- 'clay loam'
} else if(clay < 40 & clay >= 27 & sand <= 20) {tclass<- 'silty clay loam'
} else if(clay >= 35 & clay <= 60 & sand > 45 ) {tclass<- 'sandy clay'
} else if(clay >= 40 & clay <= 60 & silt >= 40) {tclass<- 'silty clay'
} else if(clay >= 40 & clay <= 60 & silt < 40 & sand <= 45) {tclass<- 'clay'
} else if(clay >60){tclass<- 'heavy clay'
} else {tclass<- 'texture class error'
}
}else{tclass<- NA}
if(triangle=="USDA" & tclass=="heavy clay"){tclass<- "clay"}
tclass
}
oss.texture(sand=0, silt=0, clay=100, triangle="USDA")
oss.texture(sand=0, silt=0, clay=100)
library(raster)
?extract
?onsoilsurvey::oss.texture
devtools::document()
rm(oss.texture)
devtools::document()
devtools::check()
devtools::document()
?oss.texture.r
load_all()
devtools::load_all()
?oss.texture.r
require(sp)
require(raster)
require(rasterVis)
require(RColorBrewer)
# create sample data which includes all combinations of sand, silt and clay
dat<- data.frame(expand.grid(sand=seq(0,100,1), silt=seq(0,100,1), clay=seq(0,100,1)))
dat$sum<- dat$sand+dat$silt+dat$clay
dat<- dat[dat$sum==100,]
dat$x<- dat$sand
dat$y<- dat$clay
coordinates(dat)<- ~x+y
gridded(dat)<- TRUE
sand<- raster(dat[1])
silt<- raster(dat[2])
clay<- raster(dat[3])
# Create sand fraction data for testing
vcs<- clay/(clay+silt+sand+clay+clay)*100
cs<- silt/(clay+silt+sand+clay+clay)*100
ms<- sand/(clay+silt+sand+clay+clay)*100
fs<- clay/(clay+silt+sand+clay+clay)*100
vfs<- clay/(clay+silt+sand+clay+clay)*100
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay)
# And we can visualize using levelplot
texture.map<- ratify(tex[[1]])
rat<- data.frame(levels(texture.map))
rat[["Texture"]]<- tex[[2]]$Class[match(rat$ID,tex$legend$Code)]
levels(texture.map)<- rat
myTheme<- rasterTheme(region=(colorRampPalette(brewer.pal(12, "Set3"))(13)))
levelplot(texture.map, par.settings=myTheme)
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay, triangle = "USDA")
#create the standardized legend
tex.legend<- data.frame(TextureClass=c("coarse sand","sand", "fine sand", "very fine sand",
"loamy coarse sand", "loamy sand", "loamy fine sand", "loamy very fine sand",
"coarse sandy loam", "sandy loam", "fine sandy loam", "very fine sandy loam",
"loam", "silt loam", "silt","sandy clay loam", "clay loam", "silty clay loam",
"sandy clay", "silty clay", "clay", "heavy clay"),
Code=c(seq(1,22,1)))
#determine the class of the objects
if(class(sand)[1]=="RasterLayer" & class(silt)[1]=="RasterLayer" & class(clay)[1]=="RasterLayer"){
#convert the raster layers to vector
s<- as.vector(round(sand,0))
si<- as.vector(round(silt,0))
c<- as.vector(round(clay,0))
#we can add the sand fractions here only if provided to the function, else we set them as NULL
if(!is.null(vcs)|!is.null(cs)|!is.null(ms)|!is.null(fs)|!is.null(vfs)){
s1<- as.vector(round(vcs,0))
s2<- as.vector(round(cs,0))
s3<- as.vector(round(ms,0))
s4<- as.vector(round(fs,0))
s5<- as.vector(round(vfs,0))
} else {s1<- s2<- s3<- s4<- s5<- NULL}
# generate matrix of xy coordinates for the raster layers
# we need to convert all NAs to a number (0 in this case) so we get all the coordinates
# since when we convert to SpatialPointsDataFrame it drops all the NA cells
xy<- sand
xy[is.na(xy)] <- 0
xy<- as(xy,"SpatialPointsDataFrame")
xy<- xy@coords
# here we use mapply to convert to texture class. We use either with or without fractions, based on inputs
if(is.null(s1)){
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, triangle=triangle)
}else{
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, vcs=s1, cs=s2, ms=s3, fs=s4, vfs=s5, triangle=trianle)}
z<- tex.legend$Code[match(z,tex.legend$TextureClass)]
z.legend<- unique(z)
z.legend<- z.legend[!is.na(z.legend)]
z.legendclass<- tex.legend$TextureClass[match(z.legend,tex.legend$Code)]
rat<- data.frame(Code=z.legend, Class=z.legendclass)
rm(z.legend,z.legendclass)
xyz<- cbind(xy,z)
tex<- rasterFromXYZ(xyz)
texout <- list("texture_raster"=tex, "legend"=rat)
# if the objects provided to the function are RasterStacks or Bricks, we need to create a for-loop to iterate
}else if(class(sand)[1]=="RasterStack" & class(silt)[1]=="RasterStack" & class(clay)[1]=="RasterStack" |
class(sand)[1]=="RasterBrick" & class(silt)[1]=="RasterBrick" & class(clay)[1]=="RasteBrick"){
#create an empty list outside the loop to store the outputs
texout<- list()
for (i in 1:nlayers(sand)){
#convert the raster layers to vector
s<- as.vector(round(sand[[i]],0))
si<- as.vector(round(silt[[i]],0))
c<- as.vector(round(clay[[i]],0))
#we can add the sand fractions here only if provided to the function, else we set them as NULL
if(!is.null(vcs)|!is.null(cs)|!is.null(ms)|!is.null(fs)|!is.null(vfs)){
s1<- as.vector(round(vcs,0))
s2<- as.vector(round(cs,0))
s3<- as.vector(round(ms,0))
s4<- as.vector(round(fs,0))
s5<- as.vector(round(vfs,0))
} else {s1<- s2<- s3<- s4<- s5<- NULL}
# generate matrix of xy coordinates for the raster layers
xy<- sand[[i]]
xy[is.na(xy)] <- 0
xy<- as(xy,"SpatialPointsDataFrame")
xy<- xy@coords
# here we use mapply to convert to texture class. We use either with or without fractions, based on inputs
if(is.null(s1)){
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, triangle=triangle)
}else{
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, vcs=s1, cs=s2, ms=s3, fs=s4, vfs=s5, triangle=triangle)}
z<- tex.legend$Code[match(z,tex.legend$TextureClass)]
z.legend<- unique(z)
z.legend<- z.legend[!is.na(z.legend)]
z.legendclass<- tex.legend$TextureClass[match(z.legend,tex.legend$Code)]
rat<- data.frame(Code=z.legend, Class=z.legendclass)
rm(z.legend,z.legendclass)
xyz<- cbind(xy,z)
tex<- rasterFromXYZ(xyz)
temp <- list("texture_raster"=tex, "legend"=rat)
texout[[i]]<- temp
}
return(texout)
# last option is that the objects provided were not RasterLayer or RasterStack or Bricks
}else{print("Input data must be RasterLayer or RasteStack or RasterBrick, please check your input objects")
}
devtools::load_all()
# create sample data which includes all combinations of sand, silt and clay
dat<- data.frame(expand.grid(sand=seq(0,100,1), silt=seq(0,100,1), clay=seq(0,100,1)))
dat$sum<- dat$sand+dat$silt+dat$clay
dat<- dat[dat$sum==100,]
dat$x<- dat$sand
dat$y<- dat$clay
coordinates(dat)<- ~x+y
gridded(dat)<- TRUE
sand<- raster(dat[1])
silt<- raster(dat[2])
clay<- raster(dat[3])
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay, triangle = "USDA")
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay, tri = "USDA")
# create sample data which includes all combinations of sand, silt and clay
dat<- data.frame(expand.grid(sand=seq(0,100,1), silt=seq(0,100,1), clay=seq(0,100,1)))
dat$sum<- dat$sand+dat$silt+dat$clay
dat<- dat[dat$sum==100,]
dat$x<- dat$sand
dat$y<- dat$clay
coordinates(dat)<- ~x+y
gridded(dat)<- TRUE
sand<- raster(dat[1])
silt<- raster(dat[2])
clay<- raster(dat[3])
tri="CSSC"
#set the triangle
tri<- tri
#create the standardized legend
tex.legend<- data.frame(TextureClass=c("coarse sand","sand", "fine sand", "very fine sand",
"loamy coarse sand", "loamy sand", "loamy fine sand", "loamy very fine sand",
"coarse sandy loam", "sandy loam", "fine sandy loam", "very fine sandy loam",
"loam", "silt loam", "silt","sandy clay loam", "clay loam", "silty clay loam",
"sandy clay", "silty clay", "clay", "heavy clay"),
Code=c(seq(1,22,1)))
#convert the raster layers to vector
s<- as.vector(round(sand,0))
si<- as.vector(round(silt,0))
c<- as.vector(round(clay,0))
# generate matrix of xy coordinates for the raster layers
# we need to convert all NAs to a number (0 in this case) so we get all the coordinates
# since when we convert to SpatialPointsDataFrame it drops all the NA cells
xy<- sand
xy[is.na(xy)] <- 0
xy<- as(xy,"SpatialPointsDataFrame")
xy<- xy@coords
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, tri=tri)
z<- tex.legend$Code[match(z,tex.legend$TextureClass)]
z.legend<- unique(z)
z.legend<- z.legend[!is.na(z.legend)]
z.legendclass<- tex.legend$TextureClass[match(z.legend,tex.legend$Code)]
rat<- data.frame(Code=z.legend, Class=z.legendclass)
rm(z.legend,z.legendclass)
xyz<- cbind(xy,z)
tex<- rasterFromXYZ(xyz)
texout <- list("texture_raster"=tex, "legend"=rat)
tri="USDA"
#set the triangle
tri<- tri
#create the standardized legend
tex.legend<- data.frame(TextureClass=c("coarse sand","sand", "fine sand", "very fine sand",
"loamy coarse sand", "loamy sand", "loamy fine sand", "loamy very fine sand",
"coarse sandy loam", "sandy loam", "fine sandy loam", "very fine sandy loam",
"loam", "silt loam", "silt","sandy clay loam", "clay loam", "silty clay loam",
"sandy clay", "silty clay", "clay", "heavy clay"),
Code=c(seq(1,22,1)))
z<- mapply(onsoilsurvey::oss.texture,sand=s, silt=si, clay=c, tri=tri)
devtools::load_all()
# create sample data which includes all combinations of sand, silt and clay
dat<- data.frame(expand.grid(sand=seq(0,100,1), silt=seq(0,100,1), clay=seq(0,100,1)))
dat$sum<- dat$sand+dat$silt+dat$clay
dat<- dat[dat$sum==100,]
dat$x<- dat$sand
dat$y<- dat$clay
coordinates(dat)<- ~x+y
gridded(dat)<- TRUE
sand<- raster(dat[1])
silt<- raster(dat[2])
clay<- raster(dat[3])
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay, tri = "USDA")
oss.texture(sand=67, silt=23, clay=10)
oss.texture(sand=67, silt=23, clay=10, vcs=60, cs=10, ms=10, fs=10, vfs=10)
devtools::document()
devtools::load_all()
?oss.texture.r
require(sp)
require(raster)
require(rasterVis)
require(RColorBrewer)
# create sample data which includes all combinations of sand, silt and clay
dat<- data.frame(expand.grid(sand=seq(0,100,1), silt=seq(0,100,1), clay=seq(0,100,1)))
dat$sum<- dat$sand+dat$silt+dat$clay
dat<- dat[dat$sum==100,]
dat$x<- dat$sand
dat$y<- dat$clay
coordinates(dat)<- ~x+y
gridded(dat)<- TRUE
sand<- raster(dat[1])
silt<- raster(dat[2])
clay<- raster(dat[3])
# Create a texture class raster without sand fractions
tex<- oss.texture.r(sand,silt,clay, tri="USDA")
# And we can visualize using levelplot
texture.map<- ratify(tex[[1]])
rat<- data.frame(levels(texture.map))
rat[["Texture"]]<- tex[[2]]$Class[match(rat$ID,tex$legend$Code)]
levels(texture.map)<- rat
myTheme<- rasterTheme(region=(colorRampPalette(brewer.pal(12, "Set3"))(13)))
levelplot(texture.map, par.settings=myTheme)
